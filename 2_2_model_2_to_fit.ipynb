{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Bidirectional, Attention, Concatenate, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"png2x\") # svg, retina, png2x ...\n",
    "mpl.style.use(\"seaborn-v0_8\")\n",
    "mpl.rcParams.update({\"figure.constrained_layout.use\": True})\n",
    "sns.set_context(\"paper\") \n",
    "sns.set_palette(\"Set2\") \n",
    "sns.set_style(\"whitegrid\") \n",
    "\n",
    "plt.rc(\"font\", family = \"Malgun Gothic\")\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# 파일 저장시 파일명의 용이성\n",
    "def now_time():\n",
    "    now = datetime.now()\n",
    "    return now.strftime('%Y%m%d_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_prep/data/_2_after_prep/corpus_method_1/sentences.pkl\",\"rb\") as f:\n",
    "    sentences = pickle.load(f)\n",
    "\n",
    "with open(\"data_prep/data/_2_after_prep/corpus_method_1/labels.pkl\",\"rb\") as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "with open(\"data_prep/data/_2_after_prep/corpus_method_1/sentences_corpus_word_index.json\",\"r\") as f:\n",
    "    sentences_corpus_word_index = json.load(f)\n",
    "\n",
    "with open(\"data_prep/data/_2_after_prep/corpus_method_1/label_corpus_word_index.json\",\"r\") as f:\n",
    "    label_corpus_word_index = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq and dense 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_prep/data/_1_before_prep/all_data_unsmile.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len = max([len(i) for i in sentences])\n",
    "text_padded = pad_sequences(sentences, maxlen=max_text_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_corpus_index_word = {sentences_corpus_word_index[key]:key for key in sentences_corpus_word_index}\n",
    "label_corpus_index_word = {label_corpus_word_index[key]:key for key in label_corpus_word_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_all = pad_sequences(sentences, maxlen=max_text_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'고향가서 피방가면 동네 부럴 친구들이랑은 뭐 거르는 거 없이 이야기하니까 막 말하게 되더라 당연히 키보드를 치거나 그러지는 않는데 말하는게 많이 거칠어지긴 해 반성해야겠네'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[5]['문장']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고향가서피방가면동네부럴친구들이랑은뭐거르는거없이이야기하니까막말하게되더라당연히키보드를치거나그러지는않는데말하는게많이거칠어지긴해반성해야겠네paddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpaddingpadding"
     ]
    }
   ],
   "source": [
    "for i in padded_all[5]:\n",
    "    print(sentences_corpus_index_word[i] , end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([107, 108, 109, 110, 111, 112, 113, 114,  79, 115,  58, 116,  11,\n",
       "        63, 117, 118, 119, 120, 102, 121, 122, 123, 124, 125, 126, 127,\n",
       "       128, 129, 102, 130, 131, 132, 133, 134, 135,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_all[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18742, 77)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(padded_all, df[df.columns[1:]],\n",
    "                                                                      train_size=15005, random_state=42)\n",
    "\n",
    "# 이렇게 분리 하는 이유 (기존의 트레인 테스트의 tsv를 하나로 합쳤기 때문)\n",
    "X_train, X_test = padded_all[:15005], padded_all[15005:] \n",
    "y_train, y_test = df[df.columns[1:]][:15005], df[df.columns[1:]][15005:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 11, True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제와 정답 라벨 확인\n",
    "(input_points, input_shape_ ), (output_points, output_shape_)= X_train.shape, y_train.shape\n",
    "input_shape_, output_shape_ , input_points == output_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38712"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_size = len(sentences_corpus_word_index)\n",
    "corpus_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈화한 모델 불러오기\n",
    "from model._2_encoder_simple_model import encoder_simple_model\n",
    "\n",
    "model = encoder_simple_model(input_shape_, corpus_size,output_shape_,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "211/211 [==============================] - 28s 86ms/step - loss: 0.4382 - accuracy: 0.3360 - val_loss: 0.2910 - val_accuracy: 0.2838\n",
      "Epoch 2/10\n",
      "211/211 [==============================] - 12s 58ms/step - loss: 0.1854 - accuracy: 0.6874 - val_loss: 0.2493 - val_accuracy: 0.5217\n",
      "Epoch 3/10\n",
      "211/211 [==============================] - 12s 58ms/step - loss: 0.1171 - accuracy: 0.8368 - val_loss: 0.1943 - val_accuracy: 0.6083\n",
      "Epoch 4/10\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.0776 - accuracy: 0.9040 - val_loss: 0.2027 - val_accuracy: 0.6163\n",
      "Epoch 5/10\n",
      "211/211 [==============================] - 15s 71ms/step - loss: 0.0562 - accuracy: 0.9341 - val_loss: 0.2237 - val_accuracy: 0.6056\n",
      "Epoch 6/10\n",
      "211/211 [==============================] - 13s 60ms/step - loss: 0.0434 - accuracy: 0.9426 - val_loss: 0.2357 - val_accuracy: 0.6103\n",
      "Epoch 7/10\n",
      "211/211 [==============================] - 13s 63ms/step - loss: 0.0342 - accuracy: 0.9533 - val_loss: 0.2431 - val_accuracy: 0.6023\n",
      "Epoch 8/10\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 0.0287 - accuracy: 0.9549 - val_loss: 0.2557 - val_accuracy: 0.6049\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.001)\n",
    "\n",
    "history_model = model.fit(X_train,y_train,\n",
    "                        validation_split=0.1,\n",
    "                        epochs=10,\n",
    "                        batch_size=64,\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_model('checkpoint__\\epoch_0004_metrics_0.0783,0.9062,0.2187,0.5793.h5')\n",
    "model.set_weights(_.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 4s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test) > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "트레쉬 홀드가 0.00일때 정확도 0.00\n",
      "트레쉬 홀드가 0.10일때 정확도 0.40\n",
      "트레쉬 홀드가 0.20일때 정확도 0.45\n",
      "트레쉬 홀드가 0.30일때 정확도 0.46\n",
      "트레쉬 홀드가 0.40일때 정확도 0.46\n",
      "트레쉬 홀드가 0.50일때 정확도 0.44\n",
      "트레쉬 홀드가 0.60일때 정확도 0.43\n",
      "트레쉬 홀드가 0.70일때 정확도 0.40\n",
      "트레쉬 홀드가 0.80일때 정확도 0.37\n",
      "트레쉬 홀드가 0.90일때 정확도 0.31\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,1,0.1):\n",
    "    pred = model.predict(X_test,verbose=0) > i\n",
    "\n",
    "    number_of_count = 0\n",
    "    correct = 0\n",
    "    for j in pred == y_test.to_numpy():\n",
    "        if False not in j:\n",
    "            correct +=1\n",
    "        number_of_count +=1\n",
    "    print(f'트레쉬 홀드가 {i:0.2f}일때 정확도 {correct/number_of_count:0.2f}',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "for i in np.arange(0.2,0.31,0.001):\n",
    "    pred = model.predict(X_test,verbose=0) > 0.2\n",
    "\n",
    "    number_of_count = 0\n",
    "    correct = 0\n",
    "    for j in pred == y_test.to_numpy():\n",
    "        if False not in j:\n",
    "            correct +=1\n",
    "        number_of_count +=1\n",
    "    print(f'트레쉬 홀드가 {i}일때 정확도',correct/number_of_count)\n",
    "\n",
    "# incoder 와 Dense 층만 있는 모델의 정확도\n",
    "# 트레쉬 홀드가 0.00일때 정확도 0.00\n",
    "# 트레쉬 홀드가 0.10일때 정확도 0.40\n",
    "# 트레쉬 홀드가 0.20일때 정확도 0.45\n",
    "# 트레쉬 홀드가 0.30일때 정확도 0.46\n",
    "# 트레쉬 홀드가 0.40일때 정확도 0.46\n",
    "# 트레쉬 홀드가 0.50일때 정확도 0.44\n",
    "# 트레쉬 홀드가 0.60일때 정확도 0.43\n",
    "# 트레쉬 홀드가 0.70일때 정확도 0.40\n",
    "# 트레쉬 홀드가 0.80일때 정확도 0.37\n",
    "# 트레쉬 홀드가 0.90일때 정확도 0.31\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정확도를 50를 넘기지 못한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       여성/가족       0.79      0.50      0.61       601\n",
      "          남성       0.83      0.71      0.76       492\n",
      "        성소수자       0.86      0.70      0.77       437\n",
      "       인종/국적       0.78      0.64      0.70       662\n",
      "          연령       0.90      0.53      0.67       221\n",
      "          지역       0.91      0.76      0.83       403\n",
      "          종교       0.83      0.78      0.80       467\n",
      "       기타 혐오       0.67      0.15      0.24       208\n",
      "       악플/욕설       0.44      0.45      0.44      1116\n",
      "       clean       0.59      0.60      0.59      1410\n",
      "        개인지칭       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.68      0.58      0.62      6129\n",
      "   macro avg       0.69      0.53      0.58      6129\n",
      "weighted avg       0.68      0.58      0.62      6129\n",
      " samples avg       0.56      0.59      0.57      6129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crazy\\miniconda3\\envs\\kdt\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\crazy\\miniconda3\\envs\\kdt\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\crazy\\miniconda3\\envs\\kdt\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred,target_names=df.columns[1:]));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
